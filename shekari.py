# -*- coding: utf-8 -*-
"""Shekari.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aBjxiOT779jlJVLugJ_6-tXBIE9tw4QK
"""

!pip install nltk
!pip install keras

!pip install HAZM
!pip install stopwords_guilannlp

import nltk
nltk.download('stopwords')

# Commented out IPython magic to ensure Python compatibility.
from hazm import *
from stopwords_guilannlp import *
import logging
import pandas as pd
import numpy as np
from numpy import random
import gensim
import nltk
import hazm
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
import re
from bs4 import BeautifulSoup
# %matplotlib inline

df = pd.read_excel('/content/dk recooord 2000.xlsx')
# Keeping only the neccessary columns
df = df[['comment','Label']]

plt.figure(figsize=(10,4))
df.Label.value_counts().plot(kind='bar');

REPLACE_BY_SPACE_RE = re.compile('[/(){}\[\]\|@,;]')
BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')
STOPWORDS = set(stopwords.words('english'))
STOP=stopwords_output("Persian", "nar")
def clean_text(text):
    """
        text: a string
        
        return: modified initial string
    """
    text = BeautifulSoup(text, "lxml").text # HTML decoding
    text = text.lower() # lowercase text
    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text
    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text
    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text
    text = ' '.join(word for word in text.split() if word not in STOP) # delete stopwors from text

    return text
    
df['comment'] = df['comment'].apply(clean_text)

df['comment'].apply(lambda x: len(x.split(' '))).sum()

X=df.comment
y=df.Label
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 12)

names=pd.read_csv('/content/Emojiiiiii.csv')
my_tags =names.Code
my_tags

from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer

nb = Pipeline([('vect', CountVectorizer()),
               ('tfidf', TfidfTransformer()),
               ('clf', MultinomialNB()),
              ])
nb.fit(X_train, y_train)

from sklearn.metrics import classification_report
y_pred = nb.predict(X_test)

print('accuracy %s' % accuracy_score(y_pred, y_test))
print(classification_report(y_test, y_pred))

from sklearn.linear_model import SGDClassifier

sgd = Pipeline([('vect', CountVectorizer()),
                ('tfidf', TfidfTransformer()),
                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=12, max_iter=5, tol=None)),
               ])
sgd.fit(X_train, y_train)



y_pred = sgd.predict(X_test)

print('accuracy %s' % accuracy_score(y_pred, y_test))
print(classification_report(y_test, y_pred))